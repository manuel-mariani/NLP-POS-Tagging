{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWqbqbGHGA_K"
   },
   "source": [
    "# Assignment 1: Part Of Speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3B9biLeVvc1"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency management\n",
    "!pip install tensorflow==2.7.0 numpy==1.21.4 pandas==1.3.4 requests==2.26.0 gensim==4.1.2 wandb==0.12.7 -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tensorflow warnings\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text pre-processing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Model definition\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Bidirectional, TimeDistributed, Dense\n",
    "\n",
    "# Data packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# System packages\n",
    "import glob\n",
    "\n",
    "# Cloning\n",
    "from copy import deepcopy\n",
    "\n",
    "# File management\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pathlib\n",
    "\n",
    "# Notebook visualization\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Typing\n",
    "from typing import Set\n",
    "\n",
    "# For GloVe wrapper\n",
    "from gensim import downloader as gensloader\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# Plotting\n",
    "import plotly.express as px\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# Metrics and utility\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUwHwCUJEFpJ"
   },
   "source": [
    "## 1 - Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oO1uB0GnGA_R"
   },
   "source": [
    "### 1.1 - Data loading\n",
    "First, we load the dataset and store it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './dependency_treebank'  # Change if dataset already present locally\n",
    "DATASET_URL = 'https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip'\n",
    "\n",
    "\n",
    "def load_dataset(ds_path: str, ds_url: str) -> pd.DataFrame:\n",
    "    # Check if dataset is already present, otherwise download it\n",
    "    if not pathlib.Path(ds_path).exists():\n",
    "        request_zip = requests.get(ds_url, stream=True)\n",
    "        zip = zipfile.ZipFile(io.BytesIO(request_zip.content))\n",
    "        zip.extractall()\n",
    "\n",
    "    # Load each file into a list\n",
    "    documents = []\n",
    "    for file_name in sorted(glob.glob(f\"{ds_path}/*.dp\")):\n",
    "        with open(file_name) as f:\n",
    "            documents.append(f.read())\n",
    "\n",
    "    # Convert each row of the documents into a list\n",
    "    raw_df = []\n",
    "    sentence_idx = 0\n",
    "    for doc_idx, doc in enumerate(documents):\n",
    "        rows = doc.split('\\n')\n",
    "        for row in rows:\n",
    "            cols = row.split('\\t')[:2]  # Ignore the last column\n",
    "            if cols == ['']:\n",
    "                sentence_idx += 1\n",
    "            else:\n",
    "                raw_df.append([doc_idx, sentence_idx, *cols])\n",
    "\n",
    "    # Finally, convert the nested list into a pandas dataframe\n",
    "    df = pd.DataFrame(raw_df, columns=['document', 'sentence', 'token', 'tag'])\n",
    "    return df\n",
    "\n",
    "\n",
    "dataset = load_dataset(DATASET_PATH, DATASET_URL)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI9ECEh3Vvc6"
   },
   "source": [
    "### 1.2 - GloVe loading\n",
    "Then, we load the GloVe embeddings (GloVe-50, to be precise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 50\n",
    "GLOVE_TYPE = f'glove-wiki-gigaword-{EMB_DIM}'\n",
    "GLOVE_FILE = f'./glove/glove-wiki-gigaword-{EMB_DIM}.kv'\n",
    "\n",
    "\n",
    "def load_glove(gl_file: str, gl_type: str) -> KeyedVectors:\n",
    "    # Load local version\n",
    "    path = pathlib.Path(gl_file)\n",
    "    if path.exists():\n",
    "        return KeyedVectors.load(gl_file)\n",
    "\n",
    "    # Otherwise download and store glove\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    glove = gensloader.load(gl_type)\n",
    "    glove.save(gl_file)\n",
    "    return glove\n",
    "\n",
    "\n",
    "glove = load_glove(GLOVE_FILE, GLOVE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GloVe loading\n",
    "print(f'cat = {glove[\"cat\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlL7FRunWqwE"
   },
   "source": [
    "### 1.3 - Data visualization\n",
    "One of the most important ML tasks is getting familiar with the data in order to gain a deeper insight on their structure and nature.\n",
    "\n",
    "To do so, we define a function that displays tokens with their POS tags in a human-friendlier way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this could be put in its own file to keep things clean,\n",
    "#       but to upload just one notebook we instead code-golfed a bit :)\n",
    "\n",
    "# Define a mapping between POS tags, their meaning and some colors\n",
    "from collections import defaultdict\n",
    "\n",
    "tag_map = {\n",
    "    'CC': ('Coordin. Conjunction', '#c18401'),\n",
    "    'TO': ('“to”', '#c18401'),\n",
    "    'DT': ('Determiner', '#c18401'),\n",
    "    'UH': ('Interjection', '#c18401'),\n",
    "    'EX': ('Existential ‘there', '#c18401'),\n",
    "    'MD': ('Modal can', '#c18401'),\n",
    "    'LS': ('List item marker', '#c18401'),\n",
    "    'IN': ('Preposition/sub-conj', '#c18401'),\n",
    "    'CD': ('Cardinal number', '#282828'),\n",
    "    'FW': ('Foreign word', '#282828'),\n",
    "    'NN': ('Noun, singular/mass', '#282828'),\n",
    "    'NNS': ('Noun, plural', '#282828'),\n",
    "    'NNP': ('Proper noun, singul.', '#282828'),\n",
    "    'NNPS': ('Proper noun, plural', '#282828'),\n",
    "    'JJ': ('Adjective', '#50a14f'),\n",
    "    'JJR': ('Adj. comparative ', '#50a14f'),\n",
    "    'JJS': ('Adj. superlative ', '#50a14f'),\n",
    "    'VB': ('Verb, base form', '#e45649'),\n",
    "    'VBD': ('Verb, past tense ', '#e45649'),\n",
    "    'VBG': ('Verb, gerund ', '#e45649'),\n",
    "    'VBN': ('Verb, past particip. ', '#e45649'),\n",
    "    'VBP': ('Verb, non-3sg pres', '#e45649'),\n",
    "    'VBZ': ('Verb, 3sg pres ', '#e45649'),\n",
    "    'WDT': ('Wh-determiner', '#4078f2'),\n",
    "    'WP': ('Wh-pronoun', '#4078f2'),\n",
    "    'WP$': (' Possessive wh-', '#4078f2'),\n",
    "    'WRB': ('Wh-adverb how', '#4078f2'),\n",
    "    'PDT': ('Predeterminer ', '#4078f2'),\n",
    "    'POS': ('Possessive ending', '#4078f2'),\n",
    "    'PP': ('Personal pronoun', '#4078f2'),\n",
    "    'PP$': (' Possessive pronoun ', '#4078f2'),\n",
    "    'RB': ('Adverb', '#a626a4'),\n",
    "    'RBR': ('Adverb, comparative', '#a626a4'),\n",
    "    'RBS': ('Adverb, superlative', '#a626a4'),\n",
    "    'RP': ('Particle', '#a626a4'),\n",
    "}\n",
    "tag_map = defaultdict(lambda: ('', '#282828'), tag_map)\n",
    "\n",
    "\n",
    "def display_pos_tagging(tokens: pd.Series,\n",
    "                        predicted_tags: pd.Series,\n",
    "                        correct_tags: pd.Series = None,\n",
    "                        limit=1000):\n",
    "    # If no correct tags are passed, we ignore the \"error highlighting\"\n",
    "    if correct_tags is None:\n",
    "        correct_tags = predicted_tags\n",
    "\n",
    "    # Limit the inputs\n",
    "    tokens = tokens[:limit]\n",
    "    predicted_tags = predicted_tags[:limit]\n",
    "    correct_tags = correct_tags[:limit]\n",
    "\n",
    "    # Iterate through tokens and tags, generating styled HTML based on the tags\n",
    "    html_sequence = []\n",
    "    for token, tag, correct in zip(tokens, predicted_tags, correct_tags):\n",
    "        tag_meaning = tag_map[tag][0]\n",
    "        err = 'pos-error' if tag != correct else ''\n",
    "        h = f'<div class=\"token {tag} {err}\">{token} <span class=\"tag\">[{tag}] {tag_meaning}</span></div>'\n",
    "        if tag == '.':\n",
    "            h += '<div class=\"separator\"/>'\n",
    "        html_sequence.append(h)\n",
    "    html_body = '<div class=\"pos-visualizer\">'\n",
    "    html_body += ' '.join(html_sequence) + '</div>'\n",
    "\n",
    "    # Generate the style (WARNING: CSS lies ahead)\n",
    "    html_style = \"\"\"\n",
    "\t<style>\n",
    "\t.pos-visualizer { padding: 32px; background-color: #FEFEFE; border-left:solid 1px grey;}\n",
    "\t.token { position:relative; display:inline-block; font-size:16px;}\n",
    "\t.token .tag { \n",
    "\t\tvisibility:hidden; width: 120px; text-align:center; position:absolute;\n",
    "\t\twidth: 160px; background-color: #282828; color: #fff; border-radius: 6px;\n",
    "\t\tz-index: 1; bottom: 100%; left: 50%; margin-left:-80px; font-size:12px;\n",
    "\t}\n",
    "\t.pos-error { text-decoration: underline solid #F94144;}\n",
    "\t.separator { margin-top:12px }\n",
    "\t.token:hover .tag { visibility:visible }\n",
    "\t\"\"\"\n",
    "    html_style += '\\n'.join((f'.{tag} {{color:{tag_map[tag][1]};}}'\n",
    "                             for tag in predicted_tags.unique()))\n",
    "    html_style += '</style>'\n",
    "\n",
    "    # Display the HTML in the cell's output\n",
    "    display(HTML(html_style + html_body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some sample POS tagging (hover on text for tag meaning)\n",
    "predicted_example = dataset['tag'].copy()\n",
    "predicted_example[0:8] = 'CD'  # Wrong prediction example for the first 8 words\n",
    "display_pos_tagging(dataset['token'],\n",
    "                    predicted_example,\n",
    "                    dataset['tag'],\n",
    "                    limit=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJwW2BJ_Eted"
   },
   "source": [
    "### 1.4 - Pre-processing\n",
    "Our dataset is already relatively clean; however, one point that might be worth considering is how to handle lowercase conversions. Some tokens in our dataset will be intrinsically capitalized (e.g. proper nouns, the personal pronoun \"I\"), whereas some other will be capitalized only because they follow a period in the sentence they occur in.\n",
    "\n",
    "One might think of converting a token to lowercase based on its tag (e.g. if a token is a proper noun, keep it capitalized); however, to be fair, this could only be done on the training set, since in a real scenario test-set tags would be unknown.\n",
    "\n",
    "Anyway, all these considerations hold only if GloVe contains embeddings of capitalized words; if that's not the case, every word we keep as capitalized will be classified as OOV when matched with GloVe, even when their lowercase embedding actually exists.\n",
    "\n",
    "As it turns out, Glove does not encode capitalized words:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_capitalized = len(\n",
    "    list(filter(lambda w: w[0].isupper(), glove.key_to_index.keys())))\n",
    "\n",
    "print(f'GloVe-50 encodes {num_capitalized} capitalized words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kqy2eiLVvdC"
   },
   "source": [
    "Therefore, we will be forced to convert all tokens to lowercase.\n",
    "\n",
    "We are also interested to see which \"special\" tokens are encoded in GloVe, i.e. punctuation, quotation marks, and tokens such as \"-LRB-\" and \"-RRB-\", which in our dataset replace \"(\" and \")\", respectively.\n",
    "\n",
    "As it turns out, GloVe contains every special symbol we care about, except for tokens reserved to brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\n",
    "    *',.:;\"`$#£!%/?^-()[]{}_', \"''\", \"``\", \"--\", \"-LRB-\", \"-RRB-\", \"-LSB-\",\n",
    "    \"-RSB-\", \"-LCB-\", \"-RCB-\"\n",
    "]\n",
    "for st in special_tokens:\n",
    "    if st not in glove:\n",
    "        print(f\"GloVe does not contain token {st}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2B391arVvdD"
   },
   "source": [
    "Based on the previous considerations, we convert all tokens to lowercase and replace \"-LRB\"-like symbols with the corresponding bracket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the brackets\n",
    "for token, bracket in [('-LRB-', '('), ('-RRB-', ')'), ('-LSB-', '['),\n",
    "                       ('-RSB-', ']'), ('-LCB-', '{'), ('-RCB-', '}')]:\n",
    "    dataset.loc[dataset.token == token, 'token'] = bracket\n",
    "\n",
    "# Convert dataset tokens to lowercase\n",
    "dataset.loc[:, 'token'] = dataset['token'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLuhT_wCVvdE"
   },
   "source": [
    "### 1.5 - Splitting\n",
    "After pre-processing the data, we can split the dataset into train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DOC_UB = 99\n",
    "TEST_DOC_LB = 150\n",
    "\n",
    "ds_train = dataset[dataset['document'].le(TRAIN_DOC_UB)]\n",
    "ds_val = dataset[dataset['document'].between(\n",
    "    TRAIN_DOC_UB, TEST_DOC_LB, inclusive='neither')].reset_index()\n",
    "ds_test = dataset[dataset['document'].ge(TEST_DOC_LB)].reset_index()\n",
    "\n",
    "print_split = lambda df: f\"{df.groupby('document').ngroups} documents, {len(df)} tokens\"\n",
    "print(f\"\"\"Dataset split: \n",
    "    TRAIN: {print_split(ds_train)}\n",
    "    VALIDATION: {print_split(ds_val)}\n",
    "    TEST: {print_split(ds_test)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70PQNGtHVvdE"
   },
   "source": [
    "### 1.6 - OOV Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dii_iOaHI4t1"
   },
   "source": [
    "#### 1.6.1 - OOV Analysis\n",
    "First of all, let us take a look at how many Out-Of-Vocabulary tokens (w.r.t. GloVe) our dataset contains. In order to simulate a real-world scenario, in which test samples are not readily available at training time, we are going to check (and then handle) OOVs *incrementally*; that is, we will consider:\n",
    "* **OOV1:** training-set tokens which are not found in V1 = GloVe.\n",
    "* **OOV2:** validation-set tokens which are not found in V2 = `union(`V1, OOV1`)`.\n",
    "* **OOV3:** test-set tokens which are not found in V3 = `union(`V2, OOV2`)`.\n",
    "\n",
    "Our final vocabulary, which will provide encodings to our model(s), is V4 = `union(`V3, OOV3`)` = `union(`GloVe, OOV1, OOV2, OOV3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_keys = set(glove.key_to_index.keys())\n",
    "oov1 = set(ds_train['token']) - glove_keys\n",
    "v2 = glove_keys.union(oov1)\n",
    "oov2 = set(ds_val['token']) - v2\n",
    "v3 = v2.union(oov2)\n",
    "oov3 = set(ds_test['token']) - v3\n",
    "\n",
    "print(f'OOV1:  {len(oov1)} tokens')\n",
    "print(f'OOV2:  {len(oov2)} tokens')\n",
    "print(f'OOV3:  {len(oov3)} tokens')\n",
    "l = len(oov1) + len(oov2) + len(oov3)\n",
    "print(\n",
    "    f'Total: {l} tokens ({l / len(set(dataset[\"token\"])) * 100:.2f}% of dataset)'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJkqb0b9VvdH"
   },
   "source": [
    "#### 1.6.2 - Adding OOVs to GloVe\n",
    "We can now add OOV tokens to the GloVe vocabulary. Many strategies can be adopted to encode OOVs as vectors:\n",
    "1. Static embeddings with the same vector for all OOV tokens (e.g. zeros).\n",
    "2. Random embeddings. \n",
    "3. Computing an embedding as some statistic involving neighboring tokens (e.g. their mean).\n",
    "\n",
    "Two observations can guide us in the choice of an embedding strategy:\n",
    "* OOV tokens are not negligible (about 6% of the *total* dataset).\n",
    "* Our GloVe embeddings will not undergo further training, therefore fixed or random embedding values will not be refined during the training process.\n",
    "\n",
    "For the two reasons above, given an OOV token, we will compute its embedding as the mean of its left and right neighbors across all its occurrences throughout the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_neighbor_mean(oov_token: str, df: pd.DataFrame,\n",
    "                          embeddings: KeyedVectors) -> np.ndarray:\n",
    "    # Find indexes where the oov token appears, and shift them by -1 +1\n",
    "    indexes = df.index[df['token'] == oov_token].values\n",
    "    indexes = np.concatenate((indexes - 1, indexes + 1))\n",
    "\n",
    "    # For each oov word index, look at the left and right until a word with embedding has been found\n",
    "    neighbor_embeddings = []\n",
    "    for idx in indexes:\n",
    "        for direction in (range(idx - 1, -1, -1), range(idx + 1, len(df))):\n",
    "            for i in direction:\n",
    "                tok = df['token'].iloc[i]\n",
    "                if tok not in embeddings:\n",
    "                    continue\n",
    "                vector = embeddings[tok]\n",
    "                neighbor_embeddings.append(vector)\n",
    "                break\n",
    "\n",
    "    return np.mean(neighbor_embeddings, axis=0)\n",
    "\n",
    "\n",
    "def add_oovs(oov_tokens: Set, df: pd.DataFrame,\n",
    "             embeddings: KeyedVectors) -> KeyedVectors:\n",
    "    # Clone the embedding (KeyedVectors does not have a clone method)\n",
    "    emb_filled = deepcopy(embeddings)\n",
    "\n",
    "    # Estimate the OOV embeddings\n",
    "    keys, values = [], []\n",
    "    for oov in oov_tokens:\n",
    "        vector = compute_neighbor_mean(oov, df, emb_filled)\n",
    "        keys.append(oov)\n",
    "        values.append(vector)\n",
    "    # Add the estimates to the embedding\n",
    "    emb_filled.add_vectors(keys, values)\n",
    "    return emb_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 = union(Glove, OOV1)\n",
    "# where neighbors of OOV1 are taken from the trainig set\n",
    "embeddings = add_oovs(oov1, ds_train, glove)\n",
    "\n",
    "# V3 = union(V2, OOV2)\n",
    "# where neighbors of OOV2 are taken from the validation set\n",
    "embeddings = add_oovs(oov2, ds_val, embeddings)\n",
    "\n",
    "# V4 = union(V3, OOV3)\n",
    "# where neighbors of OOV3 are taken from the test set\n",
    "embeddings = add_oovs(oov3, ds_test, embeddings)\n",
    "\n",
    "# Test number of embeddings\n",
    "print(f'Number of vectors in original GloVe:                  {len(glove)}')\n",
    "print(\n",
    "    f'Number of vectors after incremental addition of OOVs: {len(embeddings)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIasDlmeJqMa"
   },
   "source": [
    "### 1.7 - Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the indexes used for word -> index -> embedding\n",
    "word_index = {k: v + 1\n",
    "              for k, v in embeddings.key_to_index.items()\n",
    "              }  # +1 because index 0...\n",
    "vocab_size = len(embeddings) + 1  # ...will be reserved to padding\n",
    "\n",
    "# Define the embedding matrix\n",
    "embedding_matrix = np.zeros(shape=(vocab_size, EMB_DIM))\n",
    "for word, index in word_index.items():\n",
    "    embedding_matrix[index] = embeddings[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test\n",
    "assert np.all(embedding_matrix[embeddings.key_to_index['cat'] +\n",
    "                               1] == embeddings['cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCdBJQmXHLNZ"
   },
   "source": [
    "### 1.8 - Data Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkaqUqR2Bfza"
   },
   "source": [
    "The input data of our model could be either whole documents or single sentences contained in those documents; we will choose sentences as input data.\n",
    "\n",
    "Tokens in each sentence will be converted to integer sequences and later fed into a static `Embedding` layer storing the matrix of Glove encodings + OOVs, which will provide the input to our model.\n",
    "\n",
    "The corresponding tags—i.e. the output of our model—will be instead one-hot encoded. The rationale behind this choice is that tags are purely categorical data, hence encoding them as integer sequences would inject a notion of ordering into the model, which however is not reflected in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function\n",
    "flatten_1d = lambda nested_list: [li[0] for li in nested_list]\n",
    "\n",
    "# Convert tokens into sequences (their vocabulary indexes)\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.word_index = word_index\n",
    "token_indexes = tokenizer.texts_to_sequences_generator(dataset['token'].array)\n",
    "token_indexes = flatten_1d(token_indexes)\n",
    "\n",
    "# Convert tags into sequences\n",
    "# (as an intermediate step before one-hot encoding them)\n",
    "tag_to_int = {k: v + 1 for v, k in enumerate(dataset['tag'].unique())}\n",
    "num_tags = len(tag_to_int) + 1\n",
    "tokenizer = Tokenizer(filters='', lower=False)\n",
    "tokenizer.word_index = tag_to_int\n",
    "tag_indexes = tokenizer.texts_to_sequences_generator(dataset['tag'].array)\n",
    "tag_indexes = flatten_1d(tag_indexes)\n",
    "\n",
    "# Augment dataset with new data\n",
    "dataset['token_index'] = token_indexes\n",
    "dataset['tag_index'] = tag_indexes\n",
    "\n",
    "# Group dataset by 'sentence', aggregating remaining data into lists\n",
    "ds_sentences = dataset.groupby(['document', 'sentence']).agg(list)\n",
    "ds_sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the distribution of sentence length in the training + validation set (leaving the test set aside) to determine what is an appropriate padded-sequence size (for batching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_len = ds_sentences.query(\n",
    "    f'document <= {TEST_DOC_LB-1}')['token'].transform(len)\n",
    "len_quantile = sentences_len.quantile(.99)\n",
    "print(\"99th percentile of sentence length in training + validation set:\",\n",
    "      len_quantile)\n",
    "\n",
    "fig = px.histogram(sentences_len, labels={'value': 'Sentence Length'})\n",
    "fig.add_vline(len_quantile,\n",
    "              annotation_text=\"99th percentile\",\n",
    "              line_color='green')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 99th percentile suggests to trim sentences that exceed 56 tokens and pad sentences with fewer tokens, in order to prevent the few outliers from causing sentence encodings to be wastefully long.  We choose pre-padding, as it has been experimentally proven to be more effective than its counterpart post-padding.\n",
    "> TODO: visto che vogliamo fare così i raffinati, a sto punto citiamo il paper come si deve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = lambda x: pad_sequences(\n",
    "    x, maxlen=int(len_quantile), padding='pre', truncating='pre')\n",
    "\n",
    "\n",
    "def get_model_data(df: pd.DataFrame, lb=0, ub=None):\n",
    "    df = df.query(f'{lb} <= document <= {ub}') if ub else df.query(\n",
    "        f'{lb} <= document')\n",
    "    toks = pad(df['token_index'])\n",
    "    tags = pad(df['tag_index'])\n",
    "    # One-hot encode tags\n",
    "    tags = to_categorical(tags, num_classes=num_tags)\n",
    "    return toks, tags\n",
    "\n",
    "\n",
    "# Build the data that will be fed to the model\n",
    "x_train, y_train = get_model_data(ds_sentences, 0, TRAIN_DOC_UB)\n",
    "x_val, y_val = get_model_data(ds_sentences, TRAIN_DOC_UB + 1, TEST_DOC_LB - 1)\n",
    "x_test, y_test = get_model_data(ds_sentences, TEST_DOC_LB)\n",
    "\n",
    "# Check shapes\n",
    "print(f\"\"\"\n",
    "X shapes [sentences x tokens]\n",
    "    x_train.shape = {x_train.shape}\n",
    "    x_val.shape   = {x_val.shape}\n",
    "    x_test.shape  = {x_test.shape}\n",
    "\n",
    "Y shapes [sentences x tags x one-hot-size]\n",
    "    y_train.shape = {y_train.shape}\n",
    "    y_val.shape   = {y_val.shape}\n",
    "    y_test.shape  = {y_test.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CyRBTMKLT1i"
   },
   "source": [
    "## 2 - Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters shared by all models models\n",
    "model_hyperparams = dict(\n",
    "    epochs=2000,\n",
    "    batch_size=512,\n",
    "    mem_units=32,\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    ")\n",
    "\n",
    "# Embedding layer hyperparameters — same for all models\n",
    "embedding_hyperparams = dict(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=EMB_DIM,\n",
    "    input_length=x_train.shape[-1],\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = model_hyperparams['mem_units']  # Number of memory units of LSTM / GRU layers\n",
    "\n",
    "# Baseline: Bidirectional LSTM + Dense layer \n",
    "bi_lstm = Sequential([\n",
    "    Embedding(**embedding_hyperparams),\n",
    "    Bidirectional(LSTM(mu, return_sequences=True)),\n",
    "    Dense(num_tags, activation='softmax'),\n",
    "], \"BiLSTM + Dense\")\n",
    "\n",
    "# Bidirectional GRU + Dense layer\n",
    "bi_gru = Sequential([\n",
    "    Embedding(**embedding_hyperparams),\n",
    "    Bidirectional((GRU(mu, return_sequences=True))),\n",
    "    Dense(num_tags, activation='softmax'),\n",
    "], \"BiGRU + Dense\")\n",
    "\n",
    "# Bidirectional LSTM + Bidirectional LSTM + Dense layer\n",
    "double_bi_lstm = Sequential([\n",
    "    Embedding(**embedding_hyperparams),\n",
    "    Bidirectional(LSTM(mu, return_sequences=True)),\n",
    "    Bidirectional(LSTM(mu, return_sequences=True)),\n",
    "    Dense(num_tags, activation='softmax'),\n",
    "], \"Double-BiLSTM + Dense\")\n",
    "\n",
    "# Bidirectional LSTM + Dense layer + Dense layer\n",
    "double_dense = Sequential([\n",
    "    Embedding(**embedding_hyperparams),\n",
    "    Bidirectional(LSTM(mu, return_sequences=True)),\n",
    "    Dense(2 * num_tags, activation='relu'),\n",
    "    Dense(num_tags, activation='softmax'),\n",
    "], \" BiLSTM + Double-Dense\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Training (and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\n",
    "        bi_lstm, bi_gru, double_bi_lstm, double_dense\n",
    "]:\n",
    "    # Initialize wandb with relevant info\n",
    "    config = model_hyperparams\n",
    "    config['model-name'] = model.name\n",
    "    run_name = model.name\n",
    "    run = wandb.init(\n",
    "        anonymous=\"must\",\n",
    "        project=\"NLP-POS-Tagging\",\n",
    "        name=run_name,\n",
    "        reinit=True,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer=config['optimizer'],\n",
    "                  loss=config['loss'],\n",
    "                  metrics=['acc'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # Fit on the data and run the validation\n",
    "    with run:\n",
    "        history = model.fit(x_train,\n",
    "                            y_train,\n",
    "                            epochs=config['epochs'],\n",
    "                            batch_size=config['batch_size'],\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            callbacks=[WandbCallback(save_model=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def to_dataframe(x, y, p) -> pd.DataFrame:\n",
    "    # Define a mapping int->token and int->tag\n",
    "    int_to_tok = {v: k for k, v in word_index.items()}\n",
    "    int_to_tag = {v: k for k, v in tag_to_int.items()}\n",
    "    convert_tok = np.vectorize(int_to_tok.get)\n",
    "    convert_tag = np.vectorize(lambda i: int_to_tag.get(i, 'PAD'))\n",
    "\n",
    "    # Convert one-hot encodings to integer indexes\n",
    "    y = np.argmax(y, axis=2)\n",
    "    p = np.argmax(p, axis=2)\n",
    "\n",
    "    # Convert integer indexes to the corresponding token/tag, skipping padding\n",
    "    raw_df = dict(token=[], tag=[], tag_predicted=[])\n",
    "    for zx, zy, zp in zip(x, y, p):\n",
    "        pad_mask = zx > 0\n",
    "        raw_df['token'] += convert_tok(zx[pad_mask]).tolist()\n",
    "        raw_df['tag'] += convert_tag(zy[pad_mask]).tolist()\n",
    "        raw_df['tag_predicted'] += convert_tag(zp[pad_mask]).tolist()\n",
    "\n",
    "    # Note: the returned df will contain truncated sentences\n",
    "    return pd.DataFrame(raw_df)\n",
    "\n",
    "\n",
    "p_val = model.predict(x_val)\n",
    "ds_val_pred = to_dataframe(x_val, y_val, p_val)\n",
    "ds_val_pred.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "display_pos_tagging(ds_val_pred['token'],\n",
    "                    ds_val_pred['tag'],\n",
    "                    ds_val_pred['tag_predicted'],\n",
    "                    limit=120)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def plot_confusion_matrix(df: pd.DataFrame):\n",
    "    corr, pred = df['tag'], df[\n",
    "        'tag_predicted']  # Extract true tags and predictions\n",
    "    labels = list(set(corr) | set(pred))  # Get the tag names\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf = confusion_matrix(corr, pred, labels=labels, normalize='true')\n",
    "\n",
    "    # Plot matrix\n",
    "    fig = px.imshow(conf,\n",
    "                    x=labels,\n",
    "                    y=labels,\n",
    "                    labels={\n",
    "                        'x': 'Predicted Tag',\n",
    "                        'y': 'True Tag',\n",
    "                        'color': 'Value'\n",
    "                    })\n",
    "    fig.update(layout_coloraxis_showscale=False)\n",
    "    fig.update_layout(width=600, height=600)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(ds_val_pred)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
