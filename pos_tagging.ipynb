{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pos_tagging.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lWqbqbGHGA_K"},"source":["# Assignment 1: Part Of Speech tagging"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGqzuX9gWqv8","executionInfo":{"status":"ok","timestamp":1637679130636,"user_tz":-60,"elapsed":3916,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}},"outputId":"e8e3d43c-d832-44b9-fe3c-01238d9ae7b8"},"source":["# Main framework\n","from tensorflow import keras\n","\n","# Data packages\n","import numpy as np\n","import pandas as pd\n","\n","# System packages\n","import os\n","import glob\n","import random\n","\n","# File management\n","import requests\n","import zipfile\n","import io\n","\n","# Types and type-annotations\n","from typing import List, Dict, Tuple\n","from collections import OrderedDict\n","\n","# To store vocabulary as .json\n","!pip install simplejson\n","import simplejson\n","\n","# Notebook visualization\n","from IPython.core.display import display, HTML\n","\n","# Seed initialization\n","random.seed(0)\n","\n","# For GloVe wrapper\n","import gensim\n","\n","# Suppress warnings\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":119,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: simplejson in /usr/local/lib/python3.7/dist-packages (3.17.6)\n"]}]},{"cell_type":"markdown","metadata":{"id":"RUwHwCUJEFpJ"},"source":["## Data Pipeline"]},{"cell_type":"markdown","metadata":{"id":"oO1uB0GnGA_R"},"source":["### Data Loading\n","First we load the data (downloading it if not present), and store it into a dataframe."]},{"cell_type":"code","metadata":{"id":"NvgnVCA8Wqv-"},"source":["DATASET_PATH = \"./dependency_treebank\"  # Change if dataset already present locally\n","DATASET_URL = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n","\n","\n","def load_dataset(ds_path: str, ds_url: str) -> pd.DataFrame:\n","    # Check if dataset is already present, otherwise download it\n","    if not os.path.isdir(ds_path):\n","        request_zip = requests.get(ds_url, stream=True)\n","        zip = zipfile.ZipFile(io.BytesIO(request_zip.content))\n","        zip.extractall()\n","\n","    # Load each file into a list\n","    documents = []\n","    for file_name in sorted(glob.glob(f\"{ds_path}/*.dp\")):\n","        with open(file_name) as f:\n","            documents.append(f.read())\n","\n","    # Convert each row of the documents into a list\n","    raw_df = []\n","    sentence_idx = 0\n","    for doc_idx, doc in enumerate(documents):\n","        rows = doc.split('\\n')\n","        for row in rows:\n","            cols = row.split('\\t')[:2]  # Ignore the last column\n","            if cols == ['']:\n","                sentence_idx += 1\n","            else:\n","                raw_df.append([doc_idx, sentence_idx, *cols])\n","\n","    # Finally, convert the nested list into a pandas dataframe\n","    df = pd.DataFrame(raw_df, columns=['document', 'sentence', 'token', 'tag'])\n","    return df\n","\n","\n","dataset = load_dataset(DATASET_PATH, DATASET_URL)\n","dataset[dataset['document'].lt(1)]  # Display the first document"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UlL7FRunWqwE"},"source":["### Data Visualization\n","To gain a deeper insight on the dataset, we define a function allowing to diplay it in a human readable way:"]},{"cell_type":"code","metadata":{"id":"1ZO2zaIhWqwE","executionInfo":{"status":"ok","timestamp":1637678900283,"user_tz":-60,"elapsed":227,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}}},"source":["# Define a mapping between POS tags, their meaning and some colors\n","tag_map = {\n","    'CC': ('Coordin. Conjunction', '#c18401'),\n","    'TO': ('“to”', '#c18401'),\n","    'DT': ('Determiner', '#c18401'),\n","    'UH': ('Interjection', '#c18401'),\n","    'EX': ('Existential ‘there', '#c18401'),\n","    'MD': ('Modal can', '#c18401'),\n","    'LS': ('List item marker', '#c18401'),\n","    'IN': ('Preposition/sub-conj', '#c18401'),\n","    'CD': ('Cardinal number', '#282828'),\n","    'FW': ('Foreign word', '#282828'),\n","    'NN': ('Noun, singular/mass', '#282828'),\n","    'NNS': ('Noun, plural', '#282828'),\n","    'NNP': ('Proper noun, singul.', '#282828'),\n","    'NNPS': ('Proper noun, plural', '#282828'),\n","    'JJ': ('Adjective', '#50a14f'),\n","    'JJR': ('Adj. comparative ', '#50a14f'),\n","    'JJS': ('Adj. superlative ', '#50a14f'),\n","    'VB': ('Verb, base form', '#e45649'),\n","    'VBD': ('Verb, past tense ', '#e45649'),\n","    'VBG': ('Verb, gerund ', '#e45649'),\n","    'VBN': ('Verb, past particip. ', '#e45649'),\n","    'VBP': ('Verb, non-3sg pres', '#e45649'),\n","    'VBZ': ('Verb, 3sg pres ', '#e45649'),\n","    'WDT': ('Wh-determiner', '#4078f2'),\n","    'WP': ('Wh-pronoun', '#4078f2'),\n","    'WP$': (' Possessive wh-', '#4078f2'),\n","    'WRB': ('Wh-adverb how', '#4078f2'),\n","    'PDT': ('Predeterminer ', '#4078f2'),\n","    'POS': ('Possessive ending', '#4078f2'),\n","    'PP': ('Personal pronoun', '#4078f2'),\n","    'PP$': (' Possessive pronoun ', '#4078f2'),\n","    'RB': ('Adverb', '#a626a4'),\n","    'RBR': ('Adverb, comparative', '#a626a4'),\n","    'RBS': ('Adverb, superlative', '#a626a4'),\n","    'RP': ('Particle', '#a626a4'),\n","}\n","\n","\n","def display_pos_tagging(tokens: pd.Series,\n","                        predicted_tags: pd.Series,\n","                        correct_tags: pd.Series = None,\n","                        limit=1000):\n","    # If no correct tags are passed, we ignore the \"error highlighting\"\n","    if correct_tags is None:\n","        correct_tags = predicted_tags\n","\n","    # Limit the inputs\n","    tokens = tokens[:limit]\n","    predicted_tags = predicted_tags[:limit]\n","    correct_tags = correct_tags[:limit]\n","\n","    # Iterate through tokens and tags, generating styled html based on the color\n","    html_sequence = []\n","    for token, tag, correct in zip(tokens, predicted_tags, correct_tags):\n","        tag_meaning = tag_map.get(tag, ('', ''))[0]\n","        err = 'error' if tag != correct else ''\n","        h = f'<div class=\"token {tag} {err}\">{token} <span class=\"tag\">[{tag}] {tag_meaning}</span></div>'\n","        if tag == '.':\n","            h += '<div class=\"separator\"/>'\n","        html_sequence.append(h)\n","    html_body = '<div class=\"pos-visualizer\">'\n","    html_body += ' '.join(html_sequence) + '</div>'\n","\n","    # Generate the style (WARNING: CSS lies ahead)\n","    html_style = \"\"\"\n","\t<style>\n","\t.pos-visualizer { margin: 32px;}\n","\t.token { position:relative; display:inline-block; font-size:16px;}\n","\t.token .tag { \n","\t\tvisibility:hidden; width: 120px; text-align:center; position:absolute;\n","\t\twidth: 160px; background-color: #282828; color: #fff; border-radius: 6px;\n","\t\tz-index: 1; bottom: 100%; left: 50%; margin-left:-80px; font-size:12px;\n","\t}\n","\t.error { text-decoration: underline solid #F94144;}\n","\t.separator { margin-top:12px }\n","\t.token:hover .tag { visibility:visible }\n","\t\"\"\"\n","    html_style += '\\n'.join(\n","        (f'.{tag} {{color:{tag_map.get(tag, (\"\", \"#282828\"))[1]};}}'\n","         for tag in predicted_tags.unique()))\n","    html_style += '</style>'\n","\n","    # Display the html in the cell's output\n","    display(HTML(html_style + html_body))"],"execution_count":110,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301},"id":"weG2xb-KWqwF","executionInfo":{"status":"ok","timestamp":1637678903508,"user_tz":-60,"elapsed":287,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}},"outputId":"9cf616eb-e0ae-4bfd-d47f-91a4870fc26a"},"source":["# Display some sample POS tagging (hover on text for tag meaning)\n","predicted_example = dataset['tag'].copy()\n","predicted_example[0:8] = 'CD'  # Wrong prediction example\n","display_pos_tagging(dataset['token'],\n","                    predicted_example,\n","                    dataset['tag'],\n","                    limit=120)"],"execution_count":111,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","\t<style>\n","\t.pos-visualizer { margin: 32px;}\n","\t.token { position:relative; display:inline-block; font-size:16px;}\n","\t.token .tag { \n","\t\tvisibility:hidden; width: 120px; text-align:center; position:absolute;\n","\t\twidth: 160px; background-color: #282828; color: #fff; border-radius: 6px;\n","\t\tz-index: 1; bottom: 100%; left: 50%; margin-left:-80px; font-size:12px;\n","\t}\n","\t.error { text-decoration: underline solid #F94144;}\n","\t.separator { margin-top:12px }\n","\t.token:hover .tag { visibility:visible }\n","\t.CD {color:#282828;}\n",".VB {color:#e45649;}\n",".DT {color:#c18401;}\n",".NN {color:#282828;}\n",".IN {color:#c18401;}\n",".JJ {color:#50a14f;}\n",".NNP {color:#282828;}\n",".. {color:#282828;}\n",".VBZ {color:#e45649;}\n","., {color:#282828;}\n",".VBG {color:#e45649;}\n",".NNS {color:#282828;}\n",".CC {color:#c18401;}\n",".VBD {color:#e45649;}\n",".VBN {color:#e45649;}\n",".RB {color:#a626a4;}\n",".TO {color:#c18401;}\n",".PRP {color:#282828;}\n",".RBR {color:#a626a4;}\n",".WDT {color:#4078f2;}\n",".VBP {color:#e45649;}\n",".RP {color:#a626a4;}</style><div class=\"pos-visualizer\"><div class=\"token CD error\">Pierre <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token CD error\">Vinken <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token CD error\">, <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token CD \">61 <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token CD error\">years <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token CD error\">old <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token CD error\">, <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token CD error\">will <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token VB \">join <span class=\"tag\">[VB] Verb, base form</span></div> <div class=\"token DT \">the <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token NN \">board <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token IN \">as <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token DT \">a <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token JJ \">nonexecutive <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token NN \">director <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token NNP \">Nov. <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token CD \">29 <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token . \">. <span class=\"tag\">[.] </span></div><div class=\"separator\"/> <div class=\"token NNP \">Mr. <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NNP \">Vinken <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token VBZ \">is <span class=\"tag\">[VBZ] Verb, 3sg pres </span></div> <div class=\"token NN \">chairman <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token IN \">of <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token NNP \">Elsevier <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NNP \">N.V. <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token DT \">the <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token NNP \">Dutch <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token VBG \">publishing <span class=\"tag\">[VBG] Verb, gerund </span></div> <div class=\"token NN \">group <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token . \">. <span class=\"tag\">[.] </span></div><div class=\"separator\"/> <div class=\"token NNP \">Rudolph <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NNP \">Agnew <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token CD \">55 <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token NNS \">years <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token JJ \">old <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token CC \">and <span class=\"tag\">[CC] Coordin. Conjunction</span></div> <div class=\"token JJ \">former <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token NN \">chairman <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token IN \">of <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token NNP \">Consolidated <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NNP \">Gold <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NNP \">Fields <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NNP \">PLC <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token VBD \">was <span class=\"tag\">[VBD] Verb, past tense </span></div> <div class=\"token VBN \">named <span class=\"tag\">[VBN] Verb, past particip. </span></div> <div class=\"token DT \">a <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token JJ \">nonexecutive <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token NN \">director <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token IN \">of <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token DT \">this <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token JJ \">British <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token JJ \">industrial <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token NN \">conglomerate <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token . \">. <span class=\"tag\">[.] </span></div><div class=\"separator\"/> <div class=\"token DT \">A <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token NN \">form <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token IN \">of <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token NN \">asbestos <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token RB \">once <span class=\"tag\">[RB] Adverb</span></div> <div class=\"token VBN \">used <span class=\"tag\">[VBN] Verb, past particip. </span></div> <div class=\"token TO \">to <span class=\"tag\">[TO] “to”</span></div> <div class=\"token VB \">make <span class=\"tag\">[VB] Verb, base form</span></div> <div class=\"token NNP \">Kent <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NN \">cigarette <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token NNS \">filters <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token VBZ \">has <span class=\"tag\">[VBZ] Verb, 3sg pres </span></div> <div class=\"token VBN \">caused <span class=\"tag\">[VBN] Verb, past particip. </span></div> <div class=\"token DT \">a <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token JJ \">high <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token NN \">percentage <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token IN \">of <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token NN \">cancer <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token NNS \">deaths <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token IN \">among <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token DT \">a <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token NN \">group <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token IN \">of <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token NNS \">workers <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token VBN \">exposed <span class=\"tag\">[VBN] Verb, past particip. </span></div> <div class=\"token TO \">to <span class=\"tag\">[TO] “to”</span></div> <div class=\"token PRP \">it <span class=\"tag\">[PRP] </span></div> <div class=\"token RBR \">more <span class=\"tag\">[RBR] Adverb, comparative</span></div> <div class=\"token IN \">than <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token CD \">30 <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token NNS \">years <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token IN \">ago <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token NNS \">researchers <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token VBD \">reported <span class=\"tag\">[VBD] Verb, past tense </span></div> <div class=\"token . \">. <span class=\"tag\">[.] </span></div><div class=\"separator\"/> <div class=\"token DT \">The <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token NN \">asbestos <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token NN \">fiber <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token NN \">crocidolite <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token VBZ \">is <span class=\"tag\">[VBZ] Verb, 3sg pres </span></div> <div class=\"token RB \">unusually <span class=\"tag\">[RB] Adverb</span></div> <div class=\"token JJ \">resilient <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token IN \">once <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token PRP \">it <span class=\"tag\">[PRP] </span></div> <div class=\"token VBZ \">enters <span class=\"tag\">[VBZ] Verb, 3sg pres </span></div> <div class=\"token DT \">the <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token NNS \">lungs <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token IN \">with <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token RB \">even <span class=\"tag\">[RB] Adverb</span></div> <div class=\"token JJ \">brief <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token NNS \">exposures <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token TO \">to <span class=\"tag\">[TO] “to”</span></div> <div class=\"token PRP \">it <span class=\"tag\">[PRP] </span></div> <div class=\"token VBG \">causing <span class=\"tag\">[VBG] Verb, gerund </span></div> <div class=\"token NNS \">symptoms <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token WDT \">that <span class=\"tag\">[WDT] Wh-determiner</span></div> <div class=\"token VBP \">show <span class=\"tag\">[VBP] Verb, non-3sg pres</span></div> <div class=\"token RP \">up <span class=\"tag\">[RP] Particle</span></div> <div class=\"token NNS \">decades <span class=\"tag\">[NNS] Noun, plural</span></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"VJwW2BJ_Eted"},"source":["### Data Pre-Processing\n","The dataset does not need much of a cleanup: the only pre-processing we need to perform is converting tokens to lowercase, so that we can create a vocabulary without ending up with two entries for the same word.\n","\n","However, we need to distinguish between words that are inherently capitalized (e.g. proper nouns) and those that are so just because they follow a period."]},{"cell_type":"markdown","metadata":{"id":"c9S666OCAE4s"},"source":["#### Analysys\n","First of all, let us check which kinds of tags produce capitalized words, and how many those words are for each tag:"]},{"cell_type":"code","metadata":{"id":"80ub4lE18bye","executionInfo":{"status":"ok","timestamp":1637678914141,"user_tz":-60,"elapsed":222,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}}},"source":["def get_capitalized_tokens(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Given a dataset, counts the number of capitalized tokens for each tag.\n","\n","    Args:\n","        df: a Pandas DataFrame with 'token' and 'tag' columns\n","\n","    Returns:\n","        A DataFrame that, for each tag, displays the number \n","        of occurrences of capitalized tokens with that tag.\n","    \"\"\"\n","    return df[dataset['token'].str[0].str.isupper()]\\\n","        .groupby('tag')\\\n","        .size()\\\n","        .sort_values(ascending=False)\\\n","        .reset_index(name='capitalized counts')"],"execution_count":112,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qZM2Ii64Wqv_","executionInfo":{"status":"ok","timestamp":1637678916903,"user_tz":-60,"elapsed":223,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}},"outputId":"c8fb72e0-a664-4086-8d4e-16baeb683704"},"source":["get_capitalized_tokens(dataset)"],"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tag</th>\n","      <th>capitalized counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NNP</td>\n","      <td>9400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DT</td>\n","      <td>1022</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>IN</td>\n","      <td>541</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>JJ</td>\n","      <td>460</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PRP</td>\n","      <td>432</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NN</td>\n","      <td>304</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NNS</td>\n","      <td>255</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>NNPS</td>\n","      <td>244</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>CC</td>\n","      <td>210</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>RB</td>\n","      <td>205</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>VBG</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>CD</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>PRP$</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>WRB</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>EX</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>VBN</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>VB</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>WP</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>VBZ</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>TO</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>JJR</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>JJS</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>$</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>VBP</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>VBD</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>RBR</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>WDT</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>PDT</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>MD</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>RBS</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>UH</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>FW</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>,</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     tag  capitalized counts\n","0    NNP                9400\n","1     DT                1022\n","2     IN                 541\n","3     JJ                 460\n","4    PRP                 432\n","5     NN                 304\n","6    NNS                 255\n","7   NNPS                 244\n","8     CC                 210\n","9     RB                 205\n","10   VBG                  49\n","11    CD                  38\n","12  PRP$                  32\n","13   WRB                  32\n","14    EX                  32\n","15   VBN                  32\n","16    VB                  28\n","17    WP                  23\n","18   VBZ                  19\n","19    TO                  18\n","20   JJR                  14\n","21   JJS                   6\n","22     $                   6\n","23   VBP                   5\n","24   VBD                   4\n","25   RBR                   3\n","26   WDT                   3\n","27   PDT                   3\n","28    MD                   2\n","29   RBS                   2\n","30    UH                   2\n","31    FW                   1\n","32     ,                   1"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","metadata":{"id":"FCnFAL4dOl9N"},"source":["The most meaningful tags are (see [here](https://sites.google.com/site/partofspeechhelp/)):\n","* `NNP`: Proper Nouns (Singular)\n","* `NNPS`: Proper Nouns (Plural)\n","* `PRP`: Personal Pronouns\n","\n","The weird ones are:\n","* `$`: Dollar mark\n","* `,`: Non-full stop break punctuation marks for the sentence\n","\n","Proper nouns are always capitalized, and we should probably leave them as such, as in this case capitalization and tag are tigthly linked to each other.\n","\n","Personal pronouns are meaningfully capitalized only in the case of \"I\", which is capitalized no matter where it occurs in a sentence. We should therefore keep \"I\" as it is and convert the other pronouns to lowecase."]},{"cell_type":"markdown","metadata":{"id":"uCvXBlpOU-gi"},"source":["When is `$` capitalized?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"hlqHQoWJWqwB","executionInfo":{"status":"ok","timestamp":1637678950276,"user_tz":-60,"elapsed":336,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}},"outputId":"29c9c572-0c9d-4cad-ea67-bbe25c303d64"},"source":["dataset[dataset['tag'] == '$'].groupby('token').size().reset_index(\n","    name='\"$\"-tag counts')"],"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>token</th>\n","      <th>\"$\"-tag counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>$</td>\n","      <td>718</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C$</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>US$</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  token  \"$\"-tag counts\n","0     $             718\n","1    C$               2\n","2   US$               4"]},"metadata":{},"execution_count":114}]},{"cell_type":"markdown","metadata":{"id":"eXFwyFG4L4us"},"source":["The `$` tag is attached not only to the dollar symbol, but also to \"C\\$\" (Canadian dollars) and \"US$\" (United States dollar), which are capitalized strings. It might make sense to leave them uppercase, as they are in some sense a label denoting a special symbol. In any case, there are just 6 of them in the whole dataset, so it probably does not matter that much."]},{"cell_type":"markdown","metadata":{"id":"6ILEUjrpk5C0"},"source":["When is `,` capitalized?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"2fK2GhE_WqwC","executionInfo":{"status":"ok","timestamp":1637678962463,"user_tz":-60,"elapsed":231,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}},"outputId":"14bdb6af-7418-4d0c-d3ad-b5d1124ec286"},"source":["tmp = dataset[dataset['token'].str[0].str.isupper()]\n","tmp[tmp['tag'] == ',']"],"execution_count":115,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentence</th>\n","      <th>token</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10454</th>\n","      <td>36</td>\n","      <td>452</td>\n","      <td>Wa</td>\n","      <td>,</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       document  sentence token tag\n","10454        36       452    Wa   ,"]},"metadata":{},"execution_count":115}]},{"cell_type":"markdown","metadata":{"id":"St5bYIJSlPM6"},"source":["What does \"Wa\" mean? and why is it tagged as `,`?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181},"id":"qYNSbUn7WqwF","executionInfo":{"status":"ok","timestamp":1637678965788,"user_tz":-60,"elapsed":235,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}},"outputId":"3b9958cb-8a26-427e-d098-d0fd450e4964"},"source":["wa_sentences = dataset[dataset['token'].eq('Wa')]['sentence']\n","wa_df = dataset[dataset['sentence'].isin(wa_sentences)]\n","display_pos_tagging(wa_df['token'], wa_df['tag'])"],"execution_count":116,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","\t<style>\n","\t.pos-visualizer { margin: 32px;}\n","\t.token { position:relative; display:inline-block; font-size:16px;}\n","\t.token .tag { \n","\t\tvisibility:hidden; width: 120px; text-align:center; position:absolute;\n","\t\twidth: 160px; background-color: #282828; color: #fff; border-radius: 6px;\n","\t\tz-index: 1; bottom: 100%; left: 50%; margin-left:-80px; font-size:12px;\n","\t}\n","\t.error { text-decoration: underline solid #F94144;}\n","\t.separator { margin-top:12px }\n","\t.token:hover .tag { visibility:visible }\n","\t.IN {color:#c18401;}\n",".NNP {color:#282828;}\n",".POS {color:#4078f2;}\n",".`` {color:#282828;}\n",".PRP {color:#282828;}\n","., {color:#282828;}\n",".'' {color:#282828;}\n",".-LRB- {color:#282828;}\n",".CD {color:#282828;}\n",".NNS {color:#282828;}\n",".$ {color:#282828;}\n",".-RRB- {color:#282828;}\n",".DT {color:#c18401;}\n",".VBP {color:#e45649;}\n",".NN {color:#282828;}\n",".TO {color:#c18401;}\n",".JJ {color:#50a14f;}\n",".MD {color:#c18401;}\n",".VB {color:#e45649;}\n",".RB {color:#a626a4;}\n",".VBN {color:#e45649;}\n",".. {color:#282828;}\n",".VBZ {color:#e45649;}\n",".CC {color:#c18401;}\n",".WRB {color:#4078f2;}</style><div class=\"pos-visualizer\"><div class=\"token IN \">In <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token NNP \">Robert <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NNP \">Whiting <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token POS \">'s <span class=\"tag\">[POS] Possessive ending</span></div> <div class=\"token `` \">`` <span class=\"tag\">[``] </span></div> <div class=\"token PRP \">You <span class=\"tag\">[PRP] </span></div> <div class=\"token NNP \">Gotta <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NNP \">Have <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token , \">Wa <span class=\"tag\">[,] </span></div> <div class=\"token '' \">'' <span class=\"tag\">[''] </span></div> <div class=\"token -LRB- \">-LRB- <span class=\"tag\">[-LRB-] </span></div> <div class=\"token NNP \">Macmillan <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token CD \">339 <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token NNS \">pages <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token $ \">$ <span class=\"tag\">[$] </span></div> <div class=\"token CD \">17.95 <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token -RRB- \">-RRB- <span class=\"tag\">[-RRB-] </span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token DT \">the <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token NNP \">Beatles <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token VBP \">give <span class=\"tag\">[VBP] Verb, non-3sg pres</span></div> <div class=\"token NN \">way <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token TO \">to <span class=\"tag\">[TO] “to”</span></div> <div class=\"token NN \">baseball <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token IN \">in <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token DT \">the <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token JJ \">Nipponese <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token NN \">version <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token PRP \">we <span class=\"tag\">[PRP] </span></div> <div class=\"token MD \">would <span class=\"tag\">[MD] Modal can</span></div> <div class=\"token VB \">be <span class=\"tag\">[VB] Verb, base form</span></div> <div class=\"token RB \">hard <span class=\"tag\">[RB] Adverb</span></div> <div class=\"token VBN \">put <span class=\"tag\">[VBN] Verb, past particip. </span></div> <div class=\"token TO \">to <span class=\"tag\">[TO] “to”</span></div> <div class=\"token VB \">call <span class=\"tag\">[VB] Verb, base form</span></div> <div class=\"token DT \">a <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token `` \">`` <span class=\"tag\">[``] </span></div> <div class=\"token NN \">game <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token . \">. <span class=\"tag\">[.] </span></div><div class=\"separator\"/> <div class=\"token '' \">'' <span class=\"tag\">[''] </span></div> <div class=\"token `` \">`` <span class=\"tag\">[``] </span></div> <div class=\"token NNP \">Wa <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token '' \">'' <span class=\"tag\">[''] </span></div> <div class=\"token VBZ \">is <span class=\"tag\">[VBZ] Verb, 3sg pres </span></div> <div class=\"token NNP \">Japanese <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token IN \">for <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token `` \">`` <span class=\"tag\">[``] </span></div> <div class=\"token NN \">team <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token NN \">spirit <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token '' \">'' <span class=\"tag\">[''] </span></div> <div class=\"token CC \">and <span class=\"tag\">[CC] Coordin. Conjunction</span></div> <div class=\"token JJ \">Japanese <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token NNS \">ballplayers <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token VBP \">have <span class=\"tag\">[VBP] Verb, non-3sg pres</span></div> <div class=\"token NNS \">miles <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token CC \">and <span class=\"tag\">[CC] Coordin. Conjunction</span></div> <div class=\"token NNS \">miles <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token IN \">of <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token PRP \">it <span class=\"tag\">[PRP] </span></div> <div class=\"token . \">. <span class=\"tag\">[.] </span></div><div class=\"separator\"/> <div class=\"token `` \">`` <span class=\"tag\">[``] </span></div> <div class=\"token PRP \">You <span class=\"tag\">[PRP] </span></div> <div class=\"token NNP \">Gotta <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NNP \">Have <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token NNP \">Wa <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token '' \">'' <span class=\"tag\">[''] </span></div> <div class=\"token VBZ \">is <span class=\"tag\">[VBZ] Verb, 3sg pres </span></div> <div class=\"token DT \">the <span class=\"tag\">[DT] Determiner</span></div> <div class=\"token RB \">often <span class=\"tag\">[RB] Adverb</span></div> <div class=\"token JJ \">amusing <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token NN \">chronicle <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token IN \">of <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token WRB \">how <span class=\"tag\">[WRB] Wh-adverb how</span></div> <div class=\"token JJ \">American <span class=\"tag\">[JJ] Adjective</span></div> <div class=\"token NNS \">ballplayers <span class=\"tag\">[NNS] Noun, plural</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token VBN \">rationed <span class=\"tag\">[VBN] Verb, past particip. </span></div> <div class=\"token TO \">to <span class=\"tag\">[TO] “to”</span></div> <div class=\"token CD \">two <span class=\"tag\">[CD] Cardinal number</span></div> <div class=\"token IN \">per <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token NN \">team <span class=\"tag\">[NN] Noun, singular/mass</span></div> <div class=\"token , \">, <span class=\"tag\">[,] </span></div> <div class=\"token VBP \">fare <span class=\"tag\">[VBP] Verb, non-3sg pres</span></div> <div class=\"token IN \">in <span class=\"tag\">[IN] Preposition/sub-conj</span></div> <div class=\"token NNP \">Japan <span class=\"tag\">[NNP] Proper noun, singul.</span></div> <div class=\"token . \">. <span class=\"tag\">[.] </span></div><div class=\"separator\"/></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"OwheraeEj7ah"},"source":["The text snipped above provides an insight on the meaning of the word \"Wa\". Also, it allows us to see that the single instance in which \"Wa\" is tagged as `,` is a labeling mistake, as the other occurrences are tagged as `NNP`. Anyway, a single token–tag combination will not have an impact on our future classification."]},{"cell_type":"markdown","metadata":{"id":"fN64zPLlAMYI"},"source":["#### Text Cleaning"]},{"cell_type":"markdown","metadata":{"id":"GPJxzC6EsOjz"},"source":["Let us now define our text cleaning:"]},{"cell_type":"code","metadata":{"id":"OFWAdfv_sNuT","executionInfo":{"status":"ok","timestamp":1637679143552,"user_tz":-60,"elapsed":223,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}}},"source":["# Define masks selecting what to convert to lowercase\n","proper_noun_mask = (dataset['tag'] != 'NNP') & (dataset['tag'] != 'NNPS')\n","personal_pronoun_mask = ((dataset['tag'] == 'PRP') & (dataset['token'] != 'I')) | (dataset['tag'] != 'PRP')\n","dollar_mark_mask = dataset['tag'] != '$'\n","\n","# Apply selective lowercase conversion to dataset\n","masked_dataset = dataset[proper_noun_mask & personal_pronoun_mask & dollar_mark_mask]\n","masked_dataset['token'] = masked_dataset['token'].map(lambda x: x.lower())\n","dataset.loc[masked_dataset.index, 'token'] = masked_dataset['token']"],"execution_count":120,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CxK2-Yyu8BT3"},"source":["And check if it worked:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"8ahyNtCi6IHH","executionInfo":{"status":"ok","timestamp":1637679145901,"user_tz":-60,"elapsed":260,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}},"outputId":"0408bd79-b2b7-4c21-fe4c-d6f377c146b5"},"source":["get_capitalized_tokens(dataset)"],"execution_count":121,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tag</th>\n","      <th>capitalized counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NNP</td>\n","      <td>9400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NNPS</td>\n","      <td>244</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>PRP</td>\n","      <td>113</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>$</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    tag  capitalized counts\n","0   NNP                9400\n","1  NNPS                 244\n","2   PRP                 113\n","3     $                   6"]},"metadata":{},"execution_count":121}]},{"cell_type":"markdown","metadata":{"id":"8B2Vsj-IGA_S"},"source":["### Data Splitting"]},{"cell_type":"code","metadata":{"id":"66aTmo6rWqwG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637679150885,"user_tz":-60,"elapsed":238,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}},"outputId":"9c07c5dd-c9c5-4edf-df89-a59b74cc139f"},"source":["train_ds = dataset[dataset['document'].lt(100)]\n","validation_ds = dataset[dataset['document'].between(100, 149)]\n","test_ds = dataset[dataset['document'].gt(149)]\n","\n","print_split = lambda df: f\"{df.groupby('document').ngroups} documents, {len(df)} samples\"\n","print(f\"\"\"Dataset split: \n","    TRAIN: {print_split(train_ds)}\n","    VALIDATION: {print_split(validation_ds)}\n","    TEST: {print_split(test_ds)}\n","\"\"\")"],"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset split: \n","    TRAIN: 100 documents, 47356 samples\n","    VALIDATION: 50 documents, 31183 samples\n","    TEST: 49 documents, 15545 samples\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"eW8zQ7RuGA_U"},"source":["### Vocabulary Creation\n","> TODO: it would probably be better to define a ``Keras.Tokenizer`` wrapper that handles vocabulary creation, embedding and OOV tokens alltogether, as done is Section 6.3 of `Tutorial2`."]},{"cell_type":"code","metadata":{"id":"yZ_pBprtJoM7","executionInfo":{"status":"ok","timestamp":1637679156136,"user_tz":-60,"elapsed":606,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}}},"source":["tokenizer = keras.preprocessing.text.Tokenizer(filters='', lower=False)\n","tokenizer.fit_on_texts(dataset['token'].values)"],"execution_count":123,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TMdjicUeyGcn"},"source":["Save the vocabulary for a more detailed inspection:"]},{"cell_type":"code","metadata":{"id":"GY4BmwDMWqwE","executionInfo":{"status":"ok","timestamp":1637679158977,"user_tz":-60,"elapsed":216,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}}},"source":["vocab_path = os.path.join(os.getcwd(), 'vocab.json')\n","\n","with open(vocab_path, 'w') as f:\n","    simplejson.dump(tokenizer.word_index, f, indent=4)"],"execution_count":124,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1WQyfBxIWqwF"},"source":["### GloVe embedding\n","After the dataset has been cleaned and pre-processed, it is possible to embed the tokens by using the GloVe embedding.\n","\n","In this case the Stanford's `glove.6B` pre-trained embedding is used. Glove 6B contains 6 billion tokens, and its size is 800MB."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTwImcfbWqwF","executionInfo":{"status":"ok","timestamp":1637664823947,"user_tz":-60,"elapsed":193782,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}},"outputId":"2356eb74-0895-4155-9859-cf1ff677bab8"},"source":["GLOVE_FOLDER_PATH = \"./glove_6b\"  # Change if embedding folder already present locally\n","GLOVE_FILENAME = \"glove.6B.50d.txt\"  # Use the 50 dimensions embedding. Can be changed\n","GLOVE_DL_URL = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n","\n","\n","def load_glove_embedding(gl_folder_path: str, gl_url: str, gl_filename: str):\n","    # Download if folder does not exist\n","    if not os.path.isdir(gl_folder_path):\n","        print(\n","            \"Downloading GloVe. This may take a while depending on internet speed.\"\n","        )\n","        request_zip = requests.get(gl_url, stream=True)\n","        zip = zipfile.ZipFile(io.BytesIO(request_zip.content))\n","        print(\"Download complete! Unzipping file...\")\n","        zip.extractall(gl_folder_path)\n","        print(f\"GloVe downloaded successfully in {gl_folder_path}\")\n","\n","    # Load the txt file into a map (word -> embedding)\n","    embedding_dict = dict()\n","    with open(os.path.join(gl_folder_path, gl_filename), 'r',\n","              encoding='utf-8') as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            vect = values[1:]\n","            embedding_dict[word] = np.array(\n","                vect, dtype='f4')  # TODO: check if we can use less bits\n","    return embedding_dict\n","\n","\n","embedding_dict = load_glove_embedding(GLOVE_FOLDER_PATH, GLOVE_DL_URL,\n","                                      GLOVE_FILENAME)\n","embedding_dict['the']  # Display an example"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading GloVe. This may take a while depending on internet speed.\n","Download complete! Unzipping file...\n","GloVe downloaded successfully in ./glove_6b\n"]},{"output_type":"execute_result","data":{"text/plain":["array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n","       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n","        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n","        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n","       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n","       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n","        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n","        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n","       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n","        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n","      dtype=float32)"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"3Pzj5a-yh6GP"},"source":["What about using a gensim [`KeyedVector`](https://radimrehurek.com/gensim/models/keyedvectors.html) object? It is ligther and provides a built-in API to query and manipulate it. Also—and maybe most importantly—is what is used in `Tutorial2` (Section 4.1), so we will be able to take inspiration from it if needed."]},{"cell_type":"code","metadata":{"id":"5UIW040ue38Z","executionInfo":{"status":"ok","timestamp":1637679193302,"user_tz":-60,"elapsed":26998,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}}},"source":["word_vectors = gensim.downloader.load(\"glove-wiki-gigaword-50\")"],"execution_count":125,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufKPiP9-hcZ9","executionInfo":{"status":"ok","timestamp":1637679200710,"user_tz":-60,"elapsed":238,"user":{"displayName":"Francesco Ballerini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-R7R-HjBq_dn0hwuUoDXC2RwAVd1JXz6dReMZ3g=s64","userId":"00684324433983888967"}},"outputId":"1f0f0916-beb2-4eda-86f1-021dc63803c6"},"source":["word_vectors['the'] "],"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n","       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n","        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n","        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n","       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n","       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n","        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n","        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n","       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n","        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n","      dtype=float32)"]},"metadata":{},"execution_count":126}]}]}